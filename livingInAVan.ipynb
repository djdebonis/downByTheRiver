{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, regexp_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests # modules for scraping html data from nltk page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as van"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the ls of ls as dataset\n",
    "salientWords = van.readData(\"salientWords.txt\")\n",
    "\n",
    "# check to see if ls is same len after reading in data from doc\n",
    "len(salientWords) == 3101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document is not same length. extra item was thrown in. pop this item to remove it from list\n",
    "salientWords.pop(3101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check len again\n",
    "len(salientWords) == 3101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code creates a dictionary called documentFrequency which determines the total use of \n",
    "# individual/unique words across *all* documents\n",
    "documentIndex = {} \n",
    "for sentIndex, sent in enumerate(salientWords):\n",
    "    for word_index, word in enumerate(sent):\n",
    "        try:\n",
    "            # checks to see if there is an existing index and, if there is & the value of the \n",
    "            # sentence doesn't already exist, it adds the value\n",
    "            documentIndex[word].add(sentIndex)\n",
    "        except:\n",
    "            # if there is not an existing index, it creates one and *then* adds the value\n",
    "            documentIndex[word] = {sentIndex}\n",
    "\n",
    "# documentIndex dictionary is indexed by the unique word. each entry is the sentence (document) #\n",
    "\n",
    "documentFrequency = {}\n",
    "\n",
    "for dictIndex, dictElement in enumerate(documentIndex):\n",
    "    documentFrequency[dictElement] = len(documentIndex[dictElement]) # add the number\n",
    "    # of documents that contain this index (word) to the new dict.\n",
    "    \n",
    "# documentFrequency is a dictionary containing 'unique_word': howManySentencesItOccursIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3101 total documents/sentences in the book\n",
      "After the data was cleaned and processed there were 30970 total words remaining\n"
     ]
    }
   ],
   "source": [
    "# calculate total documents/sent\n",
    "totalDocuments = len(salientWords)\n",
    "print(\"There are %d total documents/sentences in the book\"%(totalDocuments))\n",
    "\n",
    "# calculate total words\n",
    "wordLen = 0\n",
    "for i,e in enumerate(salientWords):\n",
    "    wordLen += len(e)\n",
    "print(\"After the data was cleaned and processed there were %d total words remaining\"%(wordLen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "termFrequencyLs = [] # create ls for term frequency (TF)\n",
    "inverseDocFrequencyLs = [] # create ls for inverse document frequency (IDF)\n",
    "tfidfLs = [] # create ls for term frequency-inverse document frequency (TF-IDF)\n",
    "for sent_index, sent in enumerate(salientWords): # loop through each document\n",
    "    # create a sep list for each document's stats\n",
    "    tempTermFrequency = [] \n",
    "    tempInverseDocFrequency = []\n",
    "    tempTfidf = []\n",
    "    docLength = len(sent) # length of the current document (how many words in this sentence)\n",
    "    counts = Counter(sent) # create a counter for unique values and their frequency per document\n",
    "    for word_index, word in enumerate(sent): # iterate through each word in the current document\n",
    "        frequencyInDoc = counts[word] # frequency of current word\n",
    "        termFrequency = frequencyInDoc / docLength # term frequency for this word in this doc\n",
    "        tempTermFrequency.append(termFrequency) \n",
    "        \n",
    "        \n",
    "        inverseDocFrequency = math.log((totalDocuments/(documentFrequency[word]))) # inverse doc\n",
    "        # frequency for this word in this doc\n",
    "        tempInverseDocFrequency.append(inverseDocFrequency)\n",
    "        \n",
    "        tfidf = (termFrequency * inverseDocFrequency) #tfidf for this word in this doc\n",
    "        tempTfidf.append(tfidf)\n",
    "    \n",
    "    # append the list of the current document to the big-boy list\n",
    "    termFrequencyLs.append(tempTermFrequency)\n",
    "    inverseDocFrequencyLs.append(tempInverseDocFrequency)\n",
    "    tfidfLs.append(tempTfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interesting. The following prints the top three TFIDF value for each document (i.e. sentence)\n",
    "## SUPER INTERESTING. THE CODE BELOW GIVES A LOT OF MEANING IN THREE WORDS PER SENTENCE.\n",
    "maximumIndexLs = []\n",
    "\n",
    "for index, ls in enumerate(tfidfLs):\n",
    "    #maximumIndex = np.argmax(ls)\n",
    "    #maximumIndexLs.append(maximumIndex)\n",
    "    #topThree = []\n",
    "    n = 3\n",
    "    topThreeIndeces = sorted(range(len(ls)), key = lambda sub: ls[sub])[-n:] # some crazy ass lambda function I found that grabs the indecies of the\n",
    "    # three largest items. if someone can explain to me how this is working that would be lovely. all i know is that it works!\n",
    "    # print(topThreeIndeces)\n",
    "    maximumIndexLs.append(topThreeIndeces)\n",
    "        \n",
    "sentenceNum = []\n",
    "wordOne = []\n",
    "wordTwo = []\n",
    "wordThree = []\n",
    "if len(maximumIndexLs) == len(salientWords): # check to make sure we can iterate over these together\n",
    "    for index, doc in enumerate(salientWords):\n",
    "        #print(\"Sentence # %d: \"%(index))\n",
    "        indexLs = maximumIndexLs[index]\n",
    "        if len(indexLs) ==3: \n",
    "            sentenceNum.append((index + 1))\n",
    "            for j in range(3):\n",
    "                tempWord = doc[(indexLs[j])]\n",
    "                #print(\"Word %d: %s\"%((j+1), tempWord))\n",
    "                if j == 0:\n",
    "                    wordOne.append(tempWord)\n",
    "                elif j == 1:\n",
    "                    wordTwo.append(tempWord)\n",
    "                elif j == 2:\n",
    "                    wordThree.append(tempWord)\n",
    "        else:\n",
    "            #print(\"Wrong number of maximums\")\n",
    "            sentenceNum.append((index+1))\n",
    "            if len(indexLs) > 0:\n",
    "                for j in range(len(indexLs)):\n",
    "                    if j == 0:\n",
    "                        wordOne.append(tempWord)\n",
    "                    elif j == 1:\n",
    "                        wordTwo.append(tempWord)\n",
    "                        \n",
    "else:\n",
    "    print(\"Not same length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceNum</th>\n",
       "      <th>wordOne</th>\n",
       "      <th>wordTwo</th>\n",
       "      <th>wordThree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>fiesty</td>\n",
       "      <td>endless</td>\n",
       "      <td>shooed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>expedition</td>\n",
       "      <td>twenty</td>\n",
       "      <td>drift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>four</td>\n",
       "      <td>forgotten</td>\n",
       "      <td>dab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>turn</td>\n",
       "      <td>pasta</td>\n",
       "      <td>shade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>ragu</td>\n",
       "      <td>waited</td>\n",
       "      <td>symmetrical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>walk</td>\n",
       "      <td>smack</td>\n",
       "      <td>rested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>juniper</td>\n",
       "      <td>shade</td>\n",
       "      <td>vista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>cows</td>\n",
       "      <td>classroom</td>\n",
       "      <td>panick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>drawn</td>\n",
       "      <td>smoldering</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>west</td>\n",
       "      <td>distant</td>\n",
       "      <td>truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentenceNum     wordOne     wordTwo    wordThree\n",
       "100          101      fiesty     endless       shooed\n",
       "101          102  expedition      twenty        drift\n",
       "102          103        four   forgotten          dab\n",
       "103          104        turn       pasta        shade\n",
       "104          105        ragu      waited  symmetrical\n",
       "105          106        walk       smack       rested\n",
       "106          107     juniper       shade        vista\n",
       "107          108        cows   classroom       panick\n",
       "108          109       drawn  smoldering        would\n",
       "109          110        west     distant        truth"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dataframe with the top three words for each sentence\n",
    "topThreeWords = pd.DataFrame(zip(sentenceNum,wordOne,wordTwo,wordThree), columns = [\"sentenceNum\", \"wordOne\", \"wordTwo\", \"wordThree\"])\n",
    "topThreeWords[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2109, 1015, 772, 2602, 3005, 2415, 2748, 1894, 373, 1290]\n"
     ]
    }
   ],
   "source": [
    "# create a set of random pointers to filter out the word sets\n",
    "random.seed(120)\n",
    "pointers = []\n",
    "\n",
    "for i in range(10):\n",
    "    ptr = random.randint(0, len(sentenceNum))\n",
    "    pointers.append(ptr)\n",
    "    \n",
    "print(pointers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceNum</th>\n",
       "      <th>wordOne</th>\n",
       "      <th>wordTwo</th>\n",
       "      <th>wordThree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>773</td>\n",
       "      <td>choice</td>\n",
       "      <td>simultameous</td>\n",
       "      <td>wants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>774</td>\n",
       "      <td>wherever</td>\n",
       "      <td>crazy</td>\n",
       "      <td>jonathan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>775</td>\n",
       "      <td>home</td>\n",
       "      <td>body</td>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentenceNum   wordOne       wordTwo wordThree\n",
       "772          773    choice  simultameous     wants\n",
       "773          774  wherever         crazy  jonathan\n",
       "774          775      home          body   growing"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out the df according to the pointer and the length of sentences. append each df to a list\n",
    "length = 3\n",
    "sets = []\n",
    "\n",
    "for index, ptr in enumerate(pointers):\n",
    "    cap = ptr + length # cap is the top index in DataFrame[ptr:cap]\n",
    "    tempDf = topThreeWords[ptr:cap]\n",
    "    sets.append(tempDf)\n",
    "    filePath = \"randomSamples/randomSet\" + str(index) + \".csv\"\n",
    "    tempDf.to_csv(filePath)\n",
    "     \n",
    "sets[2] # one is interestin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# although we already put this through a dict above, I would rather use lists\n",
    "allSalientWords = []\n",
    "\n",
    "for sentIndex, sent in enumerate(salientWords):\n",
    "    for wordIndex, word in enumerate(sent):\n",
    "        allSalientWords.append(word)\n",
    "\n",
    "len(allSalientWords)\n",
    "(\"van\" in allSalientWords) # so the word van is in salient words, so it got lost somewhere in the next two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>indexFirstTokenOccur</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>like</td>\n",
       "      <td>376</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>van</td>\n",
       "      <td>280</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>back</td>\n",
       "      <td>262</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>said</td>\n",
       "      <td>29</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>time</td>\n",
       "      <td>64</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3802</th>\n",
       "      <td>one</td>\n",
       "      <td>32</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>would</td>\n",
       "      <td>193</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>road</td>\n",
       "      <td>551</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>home</td>\n",
       "      <td>67</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>life</td>\n",
       "      <td>127</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token indexFirstTokenOccur  frequency\n",
       "3211   like                  376        211\n",
       "5866    van                  280        163\n",
       "429    back                  262        159\n",
       "4668   said                   29        158\n",
       "5592   time                   64        157\n",
       "3802    one                   32        144\n",
       "6120  would                  193        137\n",
       "4588   road                  551        129\n",
       "2688   home                   67        122\n",
       "3194   life                  127        121"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allSalientWordsArr = uniqueArr(allSalientWords)\n",
    "allSalientWordsDf = uniqueDf(allSalientWordsArr)\n",
    "allSalientWordsDf.head(10) # so if i just let it chill like this it's all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "altAxis = allSalientWordsArr.transpose()\n",
    "\n",
    "\n",
    "posTuples = nltk.pos_tag(altAxis[0])\n",
    "posLs = []\n",
    "\n",
    "for i in range(len(posTuples)):\n",
    "    tup = posTuples[i]\n",
    "    pos = tup[1]\n",
    "    posLs.append(pos)\n",
    "#posLs\n",
    "\n",
    "posArr = np.array([posLs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(allSalientWordsArr) == len(posLs):\n",
    "    final = np.hstack([allSalientWordsArr, posArr.T])\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.DataFrame(final, columns = [\"word\", \"index\", \"frequency\", \"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CD</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JJ</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNS</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RB</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VBD</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VBG</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VBN</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VBP</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  word\n",
       "0   CD   107\n",
       "1   JJ  1146\n",
       "2   NN  1886\n",
       "3  NNS   886\n",
       "4   RB   304\n",
       "5  VBD   502\n",
       "6  VBG   463\n",
       "7  VBN   218\n",
       "8  VBP   392\n",
       "9  VBZ    96"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posFrequency = finalDf.groupby([\"type\"]).count()[\"word\"] # group by part of speech tags and count values for each\n",
    "posFrequencyShort = pd.DataFrame((posFrequency[posFrequency >= 50])).reset_index()\n",
    "posFrequencyShort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "posTags = [\"CD\", \"JJ\", \"NN\", \"NNS\", \"RB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(posFrequencyShort[\"type\"], posFrequencyShort[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number</td>\n",
       "      <td>Tag</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>CC</td>\n",
       "      <td>Coordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>CD</td>\n",
       "      <td>Cardinal number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>DT</td>\n",
       "      <td>Determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>EX</td>\n",
       "      <td>Existential there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>FW</td>\n",
       "      <td>Foreign word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.</td>\n",
       "      <td>IN</td>\n",
       "      <td>Preposition or subordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.</td>\n",
       "      <td>JJR</td>\n",
       "      <td>Adjective, comparative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.</td>\n",
       "      <td>JJS</td>\n",
       "      <td>Adjective, superlative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.</td>\n",
       "      <td>LS</td>\n",
       "      <td>List item marker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.</td>\n",
       "      <td>MD</td>\n",
       "      <td>Modal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.</td>\n",
       "      <td>NN</td>\n",
       "      <td>Noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Proper noun, singular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.</td>\n",
       "      <td>NNPS</td>\n",
       "      <td>Proper noun, plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.</td>\n",
       "      <td>PDT</td>\n",
       "      <td>Predeterminer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.</td>\n",
       "      <td>POS</td>\n",
       "      <td>Possessive ending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Personal pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Possessive pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.</td>\n",
       "      <td>RB</td>\n",
       "      <td>Adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.</td>\n",
       "      <td>RBR</td>\n",
       "      <td>Adverb, comparative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.</td>\n",
       "      <td>RBS</td>\n",
       "      <td>Adverb, superlative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.</td>\n",
       "      <td>RP</td>\n",
       "      <td>Particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.</td>\n",
       "      <td>SYM</td>\n",
       "      <td>Symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.</td>\n",
       "      <td>UH</td>\n",
       "      <td>Interjection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.</td>\n",
       "      <td>VB</td>\n",
       "      <td>Verb, base form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Verb, past tense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.</td>\n",
       "      <td>VBG</td>\n",
       "      <td>Verb, gerund or present participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Verb, past participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31.</td>\n",
       "      <td>VBP</td>\n",
       "      <td>Verb, non-3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32.</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Verb, 3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33.</td>\n",
       "      <td>WDT</td>\n",
       "      <td>Wh-determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34.</td>\n",
       "      <td>WP</td>\n",
       "      <td>Wh-pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35.</td>\n",
       "      <td>WP$</td>\n",
       "      <td>Possessive wh-pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36.</td>\n",
       "      <td>WRB</td>\n",
       "      <td>Wh-adverb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1                                         2\n",
       "0   Number   Tag                               Description\n",
       "1       1.    CC                  Coordinating conjunction\n",
       "2       2.    CD                           Cardinal number\n",
       "3       3.    DT                                Determiner\n",
       "4       4.    EX                         Existential there\n",
       "5       5.    FW                              Foreign word\n",
       "6       6.    IN  Preposition or subordinating conjunction\n",
       "7       7.    JJ                                 Adjective\n",
       "8       8.   JJR                    Adjective, comparative\n",
       "9       9.   JJS                    Adjective, superlative\n",
       "10     10.    LS                          List item marker\n",
       "11     11.    MD                                     Modal\n",
       "12     12.    NN                    Noun, singular or mass\n",
       "13     13.   NNS                              Noun, plural\n",
       "14     14.   NNP                     Proper noun, singular\n",
       "15     15.  NNPS                       Proper noun, plural\n",
       "16     16.   PDT                             Predeterminer\n",
       "17     17.   POS                         Possessive ending\n",
       "18     18.   PRP                          Personal pronoun\n",
       "19     19.  PRP$                        Possessive pronoun\n",
       "20     20.    RB                                    Adverb\n",
       "21     21.   RBR                       Adverb, comparative\n",
       "22     22.   RBS                       Adverb, superlative\n",
       "23     23.    RP                                  Particle\n",
       "24     24.   SYM                                    Symbol\n",
       "25     25.    TO                                        to\n",
       "26     26.    UH                              Interjection\n",
       "27     27.    VB                           Verb, base form\n",
       "28     28.   VBD                          Verb, past tense\n",
       "29     29.   VBG        Verb, gerund or present participle\n",
       "30     30.   VBN                     Verb, past participle\n",
       "31     31.   VBP     Verb, non-3rd person singular present\n",
       "32     32.   VBZ         Verb, 3rd person singular present\n",
       "33     33.   WDT                             Wh-determiner\n",
       "34     34.    WP                                Wh-pronoun\n",
       "35     35.   WP$                     Possessive wh-pronoun\n",
       "36     36.   WRB                                 Wh-adverb"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codePage = requests.get(\"http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\")\n",
    "pageTree = html.fromstring(codePage.content)\n",
    "table = pageTree.xpath(\"//table\") #get table\n",
    "obj = pd.read_html(codePage.content)\n",
    "obj = obj[0]\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
